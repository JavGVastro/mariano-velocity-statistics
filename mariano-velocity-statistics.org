* Coherence scales in H II regions

** Plan
+ Derive velocity structure functions for H II regions of different sizes:
  + Lagoon, Carina, Tarantula
+ Compare 

** Return to project 2021

*** Other things to do maybe

**** TODO Spatial variation in the structure function
+ Once we have found the correlation length, L_0, then we can look at the large-scale (> L_0) POS variation of the small-scale (< L_0) fluctuations.
+ In particular variation in
  + Magnitude of fluctuations: \sigma(< L_0)
  + Slope of structure function
  + And even in L_0 itself
    + Although for this, we need to be working on scales biggest than the largest local L_0
+ This should be easy to do with the pandas table method of doing the structure function, since we already have all the information - we just need to partition it up

**** TODO Polarization analogy for exploring anisotropy of structure function
+ This is an old idea that I had - explained in [[file:~/Dropbox/Org/garrelt-simulations.org][file:~/Dropbox/Org/garrelt-simulations.org]]
+ Might be fun to apply to structure functions.  Could also be used on brightness fluctuations
+ I wonder if there is prior art on something similar - I imagine that the Planck people have looked at anisotropy of density structures, as compared with magnetic field
  + Yes, I have found Planck-Collaboration:2016a
    + Planck intermediate results. XXXII. The relative orientation between the magnetic field and structures traced by interstellar dust
    + https://ui.adsabs.harvard.edu/abs/2016A%26A...586A.135P/abstract
    + Section 4 explains what they did - some sort of Hessian method
    + I still think there might be room for the Stokes parameters approach
    + They also mention "anisotropic wavelet techniques", which might be interesting
+ We could call it /polfluctuarization/ or something!

*** TODO Structure function of Tarantula
+ [2021-01-26 Tue] This is the first thing I am going to do in order to reactivate the project
+ The plan is to use it for the Javier paper, which will compare structure functions and other statistics for a range of H II regions with different sizes and luminosities
+ [X] Fix my multi-threaded strucfunc implementation
  + This is in
    + github: https://github.com/will-henney/muse-strucfunc
    + local: [[file:~/Dropbox/muse-strucfunc/][file:~/Dropbox/muse-strucfunc/]]
  + Now it works again, and faster than ever!
    + Multi-threaded version on my laptop is now twice as fast as it ever was on iMac at work
    + Time to calculate structure function for 400x400 array is 27.2 s

#+begin_src python :tangle tarantula-strucfunc.py :eval no
  import sys
  from pathlib import Path
  import json
  import numpy as np
  from astropy.io import fits
  sys.path.append("../muse-strucfunc")
  import strucfunc

  try:
      LINEID = sys.argv[1]
  except:
      LINEID = "ha"

  fitsfilename = {
      "ha": "GAUS_Ha6562.8_060_Will.fits",
      "nii": "GAUS_NII6583.45_060_Will.fits",
  }
  datadir = Path("data/Tarantula/MUSE_R136toWill")

  hdulist = fits.open(datadir / fitsfilename[LINEID])

  n = None
  sb = hdulist[1].data[:n, :n].astype(np.float64)
  vv = hdulist[2].data[:n, :n].astype(np.float64)
  ss = hdulist[3].data[:n, :n].astype(np.float64)

  # Replace spurious values in the arrays
  m = ~np.isfinite(sb*vv*ss) | (sb < 0.0)
  if LINEID == "nii":
      # Remove bad patch from the [N II] map
      m = m | (sb > 6e4) 
  sb[m] = 0.0
  vv[m] = np.nanmean(vv)
  sb /= sb.max()


  rslt = strucfunc.strucfunc_numba_parallel(vv, wmap=sb, dlogr=0.15)

  good = (~m) & (sb > 0.001)
  rslt["Unweighted mean velocity"] = np.mean(vv[good])
  rslt["Unweighted sigma^2"] = np.var(vv[good])
  v0w = rslt["Weighted mean velocity"] = np.average(vv, weights=sb)
  rslt["Weighted sigma^2"] = np.average((vv - v0w)**2, weights=sb)


  class MyEncoder(json.JSONEncoder):
      def default(self, obj):
          if isinstance(obj, np.integer):
              return int(obj)
          elif isinstance(obj, np.floating):
              return float(obj)
          elif isinstance(obj, np.ndarray):
              return obj.tolist()
          else:
              return super(MyEncoder, self).default(obj)

  jsonfilename = f"tarantula-strucfunc-{LINEID}.json"
  with open(jsonfilename, "w") as f:
      json.dump(rslt, fp=f, indent=3, cls=MyEncoder)
  print(jsonfilename, end="")
#+end_src

#+begin_src sh :results file
python tarantula-strucfunc.py
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc.json]]



**** Graph of Tarantula structure function

#+begin_src python :results file :return figfile
  import json
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns

  def bfunc(r, r0, sig2, m):
      "Theoretical structure function"
      C = 1.0 / (1.0 + (r/r0)**m)
      return 2.0*sig2*(1 - C)

  data = json.load(open("tarantula-strucfunc-ha.json"))

  sns.set_color_codes()
  fig, ax = plt.subplots(figsize=(5, 5))

  figfile = "tarantula-strucfunc-plot-ha.pdf"

  pixscale = 0.2 # arcsec
  pixscale *= 0.242               # parsec
  r = pixscale * 10**np.array(data["log10 r"])
  B = np.array(data["Unweighted B(r)"])
  sig2 = data["Unweighted sigma^2"]
  B_w = np.array(data["Weighted B(r)"])
  sig2_w = data["Weighted sigma^2"]

  # Plot fit to unweighted strucfunc
  rgrid = pixscale * np.logspace(0.0, 2.7)
  r0 = np.interp(sig2, B, r)
  m = 1.22
  flabel = rf"$m = {m:.2f}$, $r_0 = {r0:.1f}$ pc, $\sigma^2 = {sig2:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0, sig2, m - 0.1),
      bfunc(rgrid, r0, sig2, m + 0.1),
      color="k", alpha=0.1,
  )
  ax.plot(rgrid, bfunc(rgrid, r0, sig2, m), color="k", label=flabel)

  # Plot points from unweighted strucfunc
  ax.plot(r, B, 'o', label="Unweighted")


  # Plot fit to weighted strucfunc
  r0_w = np.interp(sig2_w, B_w, r)
  m_w = 1.30
  flabel_w = rf"$m = {m_w:.2f}$, $r_0 = {r0_w:.1f}$ pc, $\sigma^2 = {sig2_w:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0_w, sig2_w, m_w - 0.1),
      bfunc(rgrid, r0_w, sig2_w, m_w + 0.1),
      color="k", alpha=0.05,
  )
  ax.plot(rgrid, bfunc(rgrid, r0_w, sig2_w, m_w), lw=0.5, color="k", alpha=0.5, label=flabel_w)

  # Plot points from weighted strucfunc
  ax.plot(r, B_w, 'o', ms=3, alpha=0.5, label="Flux-weighted")


  melnick_r = np.array([2.5, 7.5, 12.5, 17.5, 22.5, 27.5])
  melnick_B = np.array([2.0, 2.1, 2.2, 2.2, 2.25, 2.25]) * 18.2**2
  ax.plot(melnick_r, melnick_B, 's', label="Melnick+ (2020)", color="y", zorder=-10)


  ax.axhline(sig2, color="k", ls="--")
  ax.axhline(sig2_w, color="r", ls=":")
  ax.legend(title=r"30 Doradus H$\alpha$")
  ax.set(
      xscale = "log",
      yscale = "log",
      ylim  = [0.5, 1500],
      xlabel = "Separation, pc",
      ylabel = r"$B(r)$, (km/s)$^2$",
  )
  fig.tight_layout()
  sns.despine()
  fig.savefig(figfile)
  fig.savefig(figfile.replace(".pdf", ".jpg"))
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc-plot-ha.pdf]]


Same but for the [N II] line

#+begin_src python :results file :return figfile
  import json
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns

  def bfunc(r, r0, sig2, m):
      "Theoretical structure function"
      C = 1.0 / (1.0 + (r/r0)**m)
      return 2.0*sig2*(1 - C)

  data = json.load(open("tarantula-strucfunc-nii.json"))

  sns.set_color_codes()
  fig, ax = plt.subplots(figsize=(5, 5))

  figfile = "tarantula-strucfunc-plot-nii.pdf"

  pixscale = 0.2 # arcsec
  pixscale *= 0.242               # parsec
  r = pixscale * 10**np.array(data["log10 r"])
  B = np.array(data["Unweighted B(r)"])
  sig2 = data["Unweighted sigma^2"]
  B_w = np.array(data["Weighted B(r)"])
  sig2_w = data["Weighted sigma^2"]

  rgrid = pixscale * np.logspace(0.0, 2.7)

  # Plot fit to unweighted strucfunc
  r0 = np.interp(sig2, B, r)
  m = 0.95
  flabel = rf"$m = {m:.2f}$, $r_0 = {r0:.1f}$ pc, $\sigma^2 = {sig2:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0, sig2, m - 0.1),
      bfunc(rgrid, r0, sig2, m + 0.1),
      color="k", alpha=0.1,
  )
  ax.plot(rgrid, bfunc(rgrid, r0, sig2, m), color="k", label=flabel)

  # Plot points from unweighted strucfunc
  ax.plot(r, B, 'o', label="Unweighted")


  # Plot fit to weighted strucfunc
  r0_w = np.interp(sig2_w, B_w, r)
  m_w = 1.05
  flabel_w = rf"$m = {m_w:.2f}$, $r_0 = {r0_w:.1f}$ pc, $\sigma^2 = {sig2_w:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0_w, sig2_w, m_w - 0.1),
      bfunc(rgrid, r0_w, sig2_w, m_w + 0.1),
      color="k", alpha=0.05,
  )
  ax.plot(rgrid, bfunc(rgrid, r0_w, sig2_w, m_w), lw=0.5, color="k", alpha=0.5, label=flabel_w)

  # Plot points from weighted strucfunc
  ax.plot(r, B_w, 'o', ms=3, alpha=0.5, label="Flux-weighted")


  melnick_r = np.array([2.5, 7.5, 12.5, 17.5, 22.5, 27.5])
  melnick_B = np.array([2.0, 2.1, 2.2, 2.2, 2.25, 2.25]) * 18.2**2
  ax.plot(melnick_r, melnick_B, 's', label="Melnick+ (2020)", color="y", zorder=-10)


  ax.axhline(sig2, color="k", ls="--")
  ax.axhline(sig2_w, color="r", ls=":")
  ax.legend(title="30 Doradus [N II]")
  ax.set(
      xscale = "log",
      yscale = "log",
      ylim  = [0.5, 1500],
      xlabel = "Separation, pc",
      ylabel = r"$B(r)$, (km/s)$^2$",
  )
  fig.tight_layout()
  sns.despine()
  fig.savefig(figfile)
  fig.savefig(figfile.replace(".pdf", ".jpg"))
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc-plot-nii.pdf]]


Same but in parsec.

Distance = 50 kpc => 1 arcsec = 0.242 pc

#+begin_src python :results file :return figfile
  import json
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns

  data = json.load(open("tarantula-strucfunc.json"))

  fig, ax = plt.subplots(figsize=(5, 5))

  figfile = "tarantula-strucfunc-plot-parsec.jpg"

  pixscale = 0.2                  # arcsec
  pixscale *= 0.242               # parsec
  r = pixscale * 10**np.array(data["log10 r"])
  B = np.array(data["Unweighted B(r)"])
  sig2 = data["Unweighted sigma^2"]
  B_w = np.array(data["Weighted B(r)"])
  sig2_w = data["Weighted sigma^2"]

  ax.plot(r, B, 'o')
  ax.plot(r, B_w, 'o')
  ax.axhline(sig2, color="k", ls="--")
  ax.axhline(sig2_w, color="r", ls=":")
  ax.set(
      xscale = "log",
      yscale = "log",
      xlabel = "Separation, parsec",
      ylabel = r"$B(r)$, (km/s)$^2$",
  )
  fig.tight_layout()
  sns.despine()
  fig.savefig(figfile)
  fig.savefig(figfile.replace(".jpg", ".pdf"))
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc-plot-parsec.jpg]]



**** Sample results
What we got from test with pure python version with n = 20
#+begin_example
{'log10 r': array([0.  , 0.15, 0.3 , 0.45, 0.6 , 0.75, 0.9 , 1.05, 1.2 ]), 'Sum dv^2': array([  286.176572  ,  1816.08667744,  4456.64384807, 10247.69199721,
       15614.41156876, 17353.22440817, 39015.36434385, 40118.31285852,
        2608.48845663]), 'Sum weights': array([ 27.48855598,  50.72646818, 100.8550699 , 152.64575999,
       181.63544682, 149.66641101, 179.43422474,  99.73101336,
        13.14206985]), 'Sum w * dv^2': array([  188.07159422,  1119.13494059,  2684.97040556,  6123.48035994,
        8857.18554824,  9056.58693937, 18557.14879415, 17924.77263585,
        1209.60779833]), 'N pairs': array([ 52,  98, 191, 283, 345, 301, 382, 223,  28]), 'Unweighted B(r)': array([  5.50339562,  18.53149671,  23.33321386,  36.21092579,
        45.25916397,  57.65190833, 102.13446163, 179.90274824,
        93.16030202]), 'Weighted B(r)': array([  6.84181426,  22.06214982,  26.62206678,  40.11562693,
        48.76352993,  60.51182011, 103.42034147, 179.73117922,
        92.04088944])}
#+end_example


**** DONE Assessing the strategies
CLOSED: [2021-01-26 Tue 19:36]
+ So far I have had medium-size data sets, which have allowed the use of inefficient algorithms using pandas
+ Sizes of datsets
  + Damiani:2016a Carina
    + 866 spatial points
  + Damiani:2017b Lagoon
    + 1177 spatial points
  + Castro:2018a Tarantula (30 Dor)
    + 649 x 649 pixels => 421201 points
    + This is 400 x what I was doing before
  + Estimate of memory requirement to store all the pairs (assume 8 bytes per number)
    | N points | pairs = N^2 / 2 | Memory (GB) |
    |----------+----------------+-------------|
    |     1000 |         500000 |      0.0037 |
    |   421000 |    88620500000 |    660.2742 |
    #+TBLFM: $2=$1*$1/2::$3=8 $2 / 1024**3 ; f4
  + So that is not feasible - need to use the more efiicient algorithm.
  + Based on my tests so far, I estimate that the numba parallel algorithm should be able to do the Tarantula structure function in 27.2 (649/400)**4 = 188.5 s, or 3 minutes
    + *So that is fine*
*** Tarantula I-\sigma relation
#+begin_src python :eval no :tangle tarantula-I-sigma-hist.py 
  import sys
  from pathlib import Path
  from matplotlib import pyplot as plt
  import seaborn as sns
  import json
  import numpy as np
  from astropy.io import fits
  sys.path.append("../muse-strucfunc")
  import strucfunc

  try:
      LINEID = sys.argv[1]
  except:
      LINEID = "ha"

  try:
      METHOD = sys.argv[2]
  except:
      METHOD = "standard"

  USE_COLDEN = "colden" in METHOD
  USE_DEPTH = "depth" in METHOD

  fitsfilename = {
      "ha": "GAUS_Ha6562.8_060_Will.fits",
      "nii": "GAUS_NII6583.45_060_Will.fits",
  }
  wav0 = {"ha": 6562.8, "nii": 6583.45}
  atm_wt = {"ha": 1.0, "nii": 14.0}
  fs_var = {"ha": 10.233, "nii": 0.0}
  # Assume 1e4 K for thermal broadening
  thermal_var = 82.5 / atm_wt[LINEID]

  datadir = Path("data/Tarantula/MUSE_R136toWill")

  hdulist = fits.open(datadir / fitsfilename[LINEID])

  n = None
  sb = hdulist[1].data[:n, :n].astype(np.float64)
  vv = hdulist[2].data[:n, :n].astype(np.float64)
  ss = hdulist[3].data[:n, :n].astype(np.float64)

  # optionally use column density, instead of surface brightness
  if USE_COLDEN:
      dd = fits.open(datadir / "Density.fits")["DATA"].data[:n, :n].astype(np.float64)
      sb /= dd
  if USE_DEPTH:
      dd = fits.open(datadir / "Density.fits")["DATA"].data[:n, :n].astype(np.float64)
      sb /= dd**2


  # Convert sigma to km/s
  ss *= 3e5 / wav0[LINEID]

  # Subtract instrumental width and thermal width 
  ss = np.sqrt(ss**2 - 48.0**2 - fs_var[LINEID] - thermal_var)

  # Replace spurious values in the arrays
  m = ~np.isfinite(sb*vv*ss) | (sb < 0.0)
  if LINEID == "nii":
      # Remove bad patch from the [N II] map
      m = m | (sb > 6e4) 


  m = ~m                          # invert mask

  # additional mask for bright pixels
  # BRIGHT_THRESHOLD = 0.1*np.max(sb[m])
  BRIGHT_THRESHOLD = np.median(sb[m])
  mb = sb > BRIGHT_THRESHOLD

  # Brightness-weighted average sigma
  AV_SIG = np.average(ss[m], weights=sb[m])

  NBIN = 100
  BMAX = np.max(1.2*sb[m])
  BMIN = BMAX / 1000.0
  if USE_COLDEN:
      BMAX = 5*BRIGHT_THRESHOLD
      BMIN = BMAX / 100.0
  if USE_DEPTH:
      BMAX = 10*BRIGHT_THRESHOLD
      BMIN = BMAX / 500.0
  SMIN, SMAX = 0.0, 90.0
  VMIN, VMAX = 220.0, 330.0
  GAMMA = 1.5

  vlabel = "Centroid velocity, km/s"
  slabel = "RMS line width, km/s"
  blabel = "log10(Surface brightness)"
  if USE_COLDEN:
      blabel = "log10(Column density)"
  if USE_DEPTH:
      blabel = "log10(LOS depth)"

  fig, axes = plt.subplots(2, 2)

  linestyle = dict(lw=0.7, ls="--", color="r", alpha=0.5)

  # I - sigma
  xmin, xmax = np.log10(BMIN), np.log10(BMAX)
  ymin, ymax = SMIN, SMAX
  H, xedges, yedges = np.histogram2d(
      np.log10(sb[m]), ss[m], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  axes[0, 0].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  # Show brightness thereshold
  axes[0, 0].axvline(np.log10(BRIGHT_THRESHOLD), **linestyle)
  # Show average sigma
  axes[0, 0].axhline(AV_SIG, **linestyle)
  axes[0, 0].set(
      xlabel=blabel,
      ylabel=slabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )

  # I - V
  xmin, xmax = np.log10(BMIN), np.log10(BMAX)
  ymin, ymax = VMIN, VMAX
  H, xedges, yedges = np.histogram2d(
      np.log10(sb[m]), vv[m], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  axes[1, 0].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  # Show brightness thereshold
  axes[1, 0].axvline(np.log10(BRIGHT_THRESHOLD), **linestyle)
  axes[1, 0].set(
      xlabel=blabel,
      ylabel=vlabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )

  # V - sigma
  xmin, xmax = VMIN, VMAX
  ymin, ymax = SMIN, SMAX
  H, xedges, yedges = np.histogram2d(
      vv[m & (~mb)], ss[m & (~mb)], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  # Show average sigma
  axes[0, 1].axhline(AV_SIG, **linestyle)
  axes[0, 1].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  axes[0, 1].set(
      xlabel=vlabel,
      ylabel=slabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )


  # V - sigma but bright only
  xmin, xmax = VMIN, VMAX
  ymin, ymax = SMIN, SMAX
  H, xedges, yedges = np.histogram2d(
      vv[m & mb], ss[m & mb], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  axes[1, 1].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  # Show average sigma
  axes[1, 1].axhline(AV_SIG, **linestyle)
  axes[1, 1].set(
      xlabel=vlabel,
      ylabel=slabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )

  fig.tight_layout()

  plotfile = f"tarantula-I-sigma-hist-{LINEID}.png"
  if USE_COLDEN:
      plotfile = plotfile.replace(".", "-colden.")
  if USE_DEPTH:
      plotfile = plotfile.replace(".", "-depth.")

  fig.savefig(plotfile, dpi=200)

  print(plotfile, end="")


#+end_src

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py ha
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-ha.png]]

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py nii
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-nii.png]]

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py ha colden
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-ha-colden.png]]

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py ha depth
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-ha-depth.png]]
** I-\sigma-v plots for Orion
+ It turns out that I already did this for \sigma and u in Fig. 10, 11, 12 of Arthur:2016a
+ But I still need to combine it with I
** Two-layer hypothesis
+ This is a simple model to simultaneously explain certain aspects of the following:
  1. I-\sigma-v diagrams
  2. PDF and power spectra of surface brightness
  3. Structure functions
+ The idea is that we have N independent emission layers
  + Each layer has a constant velocity
  + Each layer has a log-normal distribution of emission measure
  + And some from of spatial power spectrum
    + We can use some way of automatically generating the surface brightness field
    + There is what I did for the appendix of the Orion paper
    + Or there is the Brownian motion method of Miville-Deschenes:2003a
      + This has adjustable power laws for the density and velocity fields
+ We then make specific predictions:
  1. For the I-\sigma-v behavior
     - This is very simple and doesn't depend on the spatial power spectrum
     - We can calculate mixing lines between two pure states
     - For \sigma-v, we have different v_1, v_2, but use the same \sigma_1, \sigma_2 = \sigma.   Then we use the equation in Garcia-Diaz:2008a to calculate the combined \sigma as a function of the surface brightness ratio S_1/S_2
       - This will be a crescent, with apex when S_1/S_2 = 1, which is maximum \sigma and a velocity half way between v_1 and v_2
     - Then we calculate the distribution of S_1/S_2 in terms of the widths of the log-normal distributions
       - For narrow distributions, we will get everything concentrated around S_1/S_2 = 1
       - But for sufficiently broad distributions, things will be more concentrated at the ends: either small or large S_1/S_2, so we should get concentrated drops at (v_1, \sigma_1) and (v_2, \sigma_2)
  2. PDF and spatial power-spectra of EM  are tuned to observations, so they are not a test
  3. Structure function can be simulated. Presumably it will have a break at same length as the power spectrum
*** Plan of action for two-layer tests
1. [ ] Calculate surface brightness PDFs from the observations
   - Do this for 30 Dor and for Orion
   - Start off with the MUSE maps for 30 Dor
     - [X] See jupyter notebook for 30 Dor
   - We already have results for Orion, but we could extend them to larger scales using the orion treasury images of the entire nebula
** General thoughts on the strucfuncs, spatial power spectrum, delta variance, etc
+ The delta variance gives something that is very similar to the structure function for the velocity
  + We see a rising curve at small separations,
+ [ ] How to interpret the y-axis in the delta variance plots?
  + It is somehow related to the variance at each scale, but the must be some constants involved since the un-normalised velocity structure function for 30 Dor saturates at 2 \sigma^2 = 500 km^2/s^2, whereas \sigma^2_\Delta from the delta variance reaches about 20 km^2/s^2
  + I multiplied it by 4 \pi and that seems to just about work
+ Relationship between structure function and delta-variance
  + This is discussed in detail in Ossenkopf:2006a
    + Theoretically, they should show the same power law slope for "steep" spectra
    + In practise, they are always similar
+ Effect of projection on the delta-variance
  + They claim that this is not affected like the structure function is
  + In that we always get the reduction by 1 in the \Delta-variance slope when passing from 3D to 2D
  + But I am not entirely convinced.  I plan to do some experiments ...
  + [2021-04-22 Thu 11:47] Results of initial experiments in notebook:
    + Taking a thin sheet (LOS depth of 16 pixels out of 256) from a fBM cube does seem to reduce the slope of the delta-variance, but we don't see a clear break in the spectrum at the scale of the LOS depth.  I need to investigate more the variation with power spectrum slope, k. Also, I should do the structure function for the thin sheets too. And calculate the spatial power spectrum for good measure.
    + There are also some interesting trends in the distribution of LOS sigma and its relation to the POS sigma. For shallow power spectra (k < 3) we see that the LOS sigma is a rather narrow distribution around 1 for the thick cloud, and is somewhat broader and around 0.8 for the thin sheet. At the same time, the distribution of centroid velocities becomes significantly narrower than in the full cube, especially for the thick cloud, but to some extent also for the thin sheet.
+ Ossenkopf:2006a also say that the question whether the centroid velocity spectrum reflects velocity variations or not is mainly a function of the relative amplitude of the density fluctuations \sigma_\rho/\rho
  + If this is below 0.5, then we mainly see velocity fluctuations
  + So Orion would be a marginal case if this were true
  + And Carina would be in the density-dominated regime
  + Note that we have to read "volumetric emission coefficient" when they say "density"
** Gravity as cause for the line widths
+ In cases where gravity is dominant, then all components should show the same velocity dispersion:
  + Ionized gas
  + Molecular gas
  + Stars
  + *This is a strong testable prediction*
    + In Orion we see that the 1-d velocity dispersion of the stars is about 3 km/s I think, which is less than the velocity dispersion of the gas
    + Also, the velocity dispersion of the molecular gas is smaller
      + [ ] We should calculate structure function from the Kong observations
  + *What about in 30 Dor?*
    + [ ] Look at molecular gas kinematics in 30 Dor
      + We have the Indebetouw:2020x observations of the 30 Dor-10 molecular cloud
        + The surface of this is the bright Ha emission at the N edge of the MUSE maps
        + The mean velocity is shown in Figure 6
      + But it would be good to find some larger scale velocity maps
      + Johan
    + H I statistics
      + Szotkowski:2019a calculate the intensity structure function and spatial power spectrum, but they do not calculate the velocity structure function, although they do use the VCA method.  They also calculate the spatial variation of the power law slopes
    + Stars do not seem to follow
+ If dynamical relaxation has occurred, then the structure function should be flat
  + So a steep structure function below the correlation scale is evidence against dynamical relaxation
  + Ha:2021u find that ONC stars are relaxed (flat structure function)
    + But they find evidence for power law at large scale for other clusters in Orion
    + Although the scales they are working at are far larger than the ones we have studied before
  + Although I suppose that we could have injection scale being the average separation between stars
    + And then turbulent cascade at smaller scales


** Reynolds number in H II regions
+ General definition:
  \[
  \mathrm{Re} = \frac{u L}{\nu} 
  \]
  + u is velocity
  + L is size
  + \nu is kinematic viscosity in cm^2/s
    + \nu = \lambda_mfp u_therm
    + viscosity is dominated by electrons with u_therm \approx 550 T_4^{1/2} km/s
      + u_therm \approx (m_p/m_e)^{1/2} c_s
    + from kappa paper: \lambda_mfp \approx 1.3e12 T_4^2 n_e^-1 cm
  + So Re = (u / u_therm) (L / \lambda_mfp)
+ Relation to Knudsen number and Mach number:
  + Kn = \lambda_mfp / L
  + Ma = u / c_s
  + => Re \approx (m_e/m_p)^{1/2} Ma / Kn  \approx 0.023 Ma / Kn
+ Relation to ionization parameter
  + U = Q / 4 \pi R_s^2 n c
    + Q is ionizing luminosity; R_s is Strömgren radius
  + From the kappa paper, I have:
    + Kn = 3.76e-12 U^-1
    + Also U = 0.0006 (Q_49 n)^{1/3}
  + Hence
    + Re \approx 6.1e9 Ma U
    + Re \approx 3.7e6 Ma (Q_49 n)^{1/3}
  + Typically, Q_49 n \approx 1e4 => U \approx 0.013
    + Re \approx 8e7 Ma
+ Taylor scale Reynolds number
  + This is Re* in Elsinga:2020a
  + They have an equation (2.4) that relates Re* to the global Re
    + we use it with their default parameters
      + D = 0.5
      + \alpha = 0.010
      + b = 0.67
    + To get
      + Re* = 9.65 Re^{1/3} [0.67 + 0.33 0.01 Re]^{1/6}
      + For Re >> 1000, this becomes 3.7 Re^{1/2}
    + So Re = 1e8 -> Re* = 3.7e4
    + If we substitute this again (full equation this time), we get
      + Re** = 717 for sub-layers
      + Re*** = 104 for sub-sub layers
    + So fact that sub-sub layers have Re*** < 150 means that they are not themselves turbulent.
+ "Significant shear layers" from Elsinga:2020a
  + They have thickness pf 4 \lambda_T
  + And velocity difference of order U, which is the large-scale velocity dispersion
  + So this velocity difference is much larger than the RMS b = |v-v'| at scale \lambda_T
    + *because the volume filling factor of the shear layers is small*, of order \lambda_T/L
  + This is repeated for the sub-layers and sub-sub layers
    + *they all have velocity differences of order U*
    + but smaller and smaller volume fractions
+ Wikipedia equations for Taylor microscale
  + This gives \lambda_T / L = sqrt(10 / Re)
    + For Re = 1e8, this gives \lambda_T = 3e-4 L
    + This is consistent with the result Re* = 3.7e4 Re, assuming same U at all scales
  + Also, \eta / L = Re^{-3/4} = 1e-6 L
    + But this is the Kolmogorov length at the mean dissipation rate
    + The Elsinga:2020a theory is that the shear layers have enhanced dissipation and smaller and smaller Kolmogorov scales with each nesting
  + So if the driving scale is 1 pc, then we have a Taylor microscale of 0.3 mpc, or 0.15 arcsec at Orion
    + And Orion has a smaller driving scale, so Taylor microscale would be tough to observe
  + Hierarchy
    + L -> L* -> L** -> L***
    + L = 1 pc -> L* = 0.3 mpc -> L** = 0.005 mpc (1 AU) -> L*** = 0.0006 mpc (0.12 AU)
    + \eta = 0.001 mpc (0.2 AU) -> \eta* = 0.0001 mpc (0.02 AU) -> \eta** = 0.00003 mpc (0.006 AU) -> stop there!  
+ *Conclusion*
  + Typical Reynolds number should be of order 1e8
  + From the analysis of Elsinga:2020z this means that the flow should support multiple nested shear layers, up to sub-sublayers
  + The Reynolds number at the Taylor scale should be smaller, but only by a factor of l_T/L
    + This is because the velocity difference is the same at all nested layers
     
** Structure functions and spatial power laws
+ Structure functions of molecular gas
  + Henshaw:2020t
  + Ubiquitous velocity fluctuations throughout the molecular interstellar medium
** LOS versus POS widths
+ Carina
  + Line widths typically have \sigma = 15 km/s, but this includes the thermal contribution.
  + thermal \sigma is 9 km/s => non-thermal is 12 km/s
  + For individual components, we have 5.6 km/s, so we have \sigma(LOS) = 2 \sigma(POS), as in Orion
+ 30 Doradus
  + We have \sigma = 55 km/s for H alpha at highest brightness
  + For Orion with the same instrument we have 48.5 km/s
  + Subtracting in quadrature gives 26 km/s for LOS \sigma
    + Note however, that 15 km/s is what Melnick et al found for the same region
      + Is this because they have decomposed the lines into components first
    + I need to check this with the original data
  + For POS \sigma we have sqrt(252) = 16 km/s
  + So, we have LOS and POS \sigma being the same if we believe Melnick, although the MUSE widths suggest LOS \sigma is 2 x higher
+ Orion
+ M8

** Comparison between regions
|             |     Q_H |  L(Ha) |    SFR |   n | R_S, pc | L, pc |   \Sigma_SFR | \ell_0, pc |   \sigma |    m | D, kpc |
|-------------+--------+--------+--------+-----+--------+-------+--------+--------+-----+------+--------|
| Orion       |   1e49 | 1.2e37 | 5.3e-5 | 1e4 |  0.101 |   0.6 | 46.862 |   0.05 | 3.1 |  1.1 |    0.4 |
| Orion large |   1e49 | 1.2e37 | 5.3e-5 | 100 |  2.184 |     4 |  1.054 |        |     |      |    0.4 |
| M8 small    |   2e49 | 2.3e37 | 1.0e-4 | 600 |  0.833 |    20 |  0.080 |    1.3 |   3 |  0.8 |    1.3 |
| M8 large    |   2e49 | 2.3e37 | 1.0e-4 |  60 |  3.868 |    20 |  0.080 |      6 |   4 |    1 |    1.3 |
| Carina      |   2e51 | 2.3e39 | 1.0e-2 | 500 |  4.368 |    15 | 14.147 |    0.5 |   4 |  0.7 |    2.0 |
| 30 Dor      | 2.5e51 | 2.9e39 | 1.3e-2 | 500 |  4.705 |    30 |  4.598 |    2.7 |  16 | 1.22 |     50 |
| NGC 604 T   |   1e51 | 1.2e39 | 5.3e-3 |  50 | 16.092 |   400 |  0.011 |     11 | 7.3 |  1.7 |    840 |
| NGC 595     |   5e50 | 5.8e38 | 2.6e-3 |  50 | 12.772 |   300 |  0.009 |     11 | 6.6 |  1.7 |    840 |
| Hubble V    |   3e49 | 3.5e37 | 1.5e-4 |  90 |  3.379 |   100 |  0.005 |    3.6 | 2.8 |  1.8 |    500 |
| Hubble X    |   6e49 | 7.0e37 | 3.1e-4 |  30 |  8.856 |   150 |  0.004 |    4.7 | 3.6 |  1.7 |    500 |
#+TBLFM: $3=$2/ 8.56e+11 ;s2::$4=4.424e-42 $3;s2::$6=($2 / 4 $pi 2.6e-13 $5**2 )**(1/3) / $pc;f3::$8=$4 / $pi ($7/1000)**2 ;f3


More recent census of stars in 30 Doradus gives slightly larger QH - Bestenlehner:2020a give 2.75e+51 /s

L(Ha) = (h\nu) \alpha_Ha VEM
Q_H = \alpha_B VEM = L(Ha) \alpha_B/\alpha_eff 1/h\nu

h\nu = 13.6 (1/4 - 1/9) eV = 3.026e-12 erg
\alpha_B / \alpha_eff = 2.6 

Q_H = 8.56e+11 L(Ha)

NGC 604: L(Ha) = 1e39 => Q_H = 1e51 erg
NGC 595: L(Ha) = 

Hubble V: L(Ha) = 1e49 en fotones => Q(H) = 2.6e49
Hubble X: L(Ha) = 2.4e49 en fotones => Q(H) = 6.24e49


** Velocity maps of Carina and Lagoon

+ Gaia-ESO spectroscopy
  + Damiani:2016a Carina
    + 10 arcmin at 2.3 kpc = 6 pc
    + 10 arcsec = 0.1 pc
    + Can analyze blue and red components separately and together
  + Damiani:2017b Lagoon
    + D = 1250 pc
    + Total extent: 0.8 deg = 17 pc
+ MUSE spectroscopy
  + McLeod:2016a Carina
    + 2 arcmin at 2.3 kpc = 1.3 pc
    + 1 arcsec = 0.01 pc
  + Mc-Leod:2016a Orion
    + 5 arcmin at 410 pc = 0.6 pc
    + 1 arcsec = 0.002 pc
    + Amplitude is about 10 km/s
  + Castro:2018a Tarantula (30 Dor)
    + These are excellent
    + 2 arcmin at 50 kpc = 30 pc
    + 1 arcsec = 0.242 pc
    + Amplitude is about 40 km/s
    + Looks like 5 arcsec is typical fluctuation scale => 1 pc
    + Anti correlation of intensity with \sigma(LOS) - see Fig 7
    + Could use density and de-extincted H\alpha to get LOS thickness
  + McLeod:2015a Eagle pillars
    + A bit too noisy to do much with
+ Longslit spectroscopy
  + Arthur:2016a Orion
    + Find scale of 0.05 pc decorrelation scale from struc func
    + Similar scale from power spectrum of brightness
    + Inner scale of 0.02 pc, but not clear what this is
** Other literature on Lagoon kinematics
+ Also see the images in introduction to my Greece talk
  + [[file:~/Dropbox/Presentations/Olympia2014/wjh-greece-2014.pdf]]
*** Relation to molecular/neutral gas
+ Tiwari:2018a have CO, etc for Lagoon region
  + Ionized gas is at negative velocities with respect to CO
    + Lada:1976a have +11 km/s LSR for CO at biggest clump
  + This is reminiscent of champagne flow, as in Orion
+ Esteban:1999a have multiple optical lines for M42 (Orion), M17 (Eagle), and M8 (Lagoon)
  + For Lagoon
    + Slit is 25 arcsec S of Hourglass
    + V(HEL) approx -2 km/s for low-ionization lines
    + Higher ionization lines are more like -10
    + Discrepant results for [O I] and [N I] but may suffer from sky line contamination
  + They find a velocity-IP correlation in all cases, indicating blue-shifted champagne flows
*** Dominant sources of ionizing radiation
+ Looks like main ionizing star (9 Sgr) is 1pc in front of cloud in Lagoon
  + From Fig 20 of Damiani:2017a
*** Prior art on Lagoon structure function
+ Chakraborty:1999a calculated the [O III] structure function of Hourglass region
  + Separations of 2-30 arcsec (so very little dynamic range)
  + As compared with up to 1800 arcsec in Damiani
  + They did something very strange to eliminate large scale gradients
  + And their absolute values are very large: saturates at 280 km^2/s^2
+ Chakraborty:1997a give [N II] velocity image but do not calculate statistics
  + And they don't even have absolute velocities
*** Previous studies of large scale kinematics
+ Haenel:1987a did FP spectroscopy of the entire nebula and has a grid at 50 arcsec resolution (0.014 deg)
  + 34 x 26 pixels = 0.5 x 0.4 degrees
  + Velocities are LSR
  + Seems to agree more or less with Damiani, given the 10 km/s difference between heliocentric and LSR
+ So this is very similar number of points to the Damiani data, but coverage is more uniform


** Stage 1 of Mariano project

*** DONE Download the Gaia-ESO datasets
CLOSED: [2018-09-25 Tue 08:41]
+ Damiani Carina
  + [[file:data/J_A+A_591_A74_table1.dat.fits]]
+ Damiani Lagoon
  + [[file:data/J_A+A_604_A135_table2.dat.fits]]

*** DONE Initial look at Carina data by Will
CLOSED: [2018-09-25 Tue 10:25]
See
 + Jupyter notebook: [[file:mariano-test.ipynb]]
 + Pure python version: [[file:mariano-test.py]]

*** TODO Initial look at Lagoon data by Mariano
+ [ ] Install required packages
+ [ ] Load data with astropy
+ [ ] Convert to pandas
+ [ ] Clean up data as necessary
+ [ ] Look at correlations
+ [ ] Make maps
+ [ ] Calculate structure functions


** Further stages
*** Obtain more data
**** MUSE data on Carina
+ McLeod:2016a best region is around "defiant finger", just to W of Keyhole.
  + That is the brightest region, and only one that overlaps the Gaia-ESO observations
  + Other regions are fainter and are in the periphery of the nebula
+ As well as the published McLeod:2016a stuff, there are new observations of the Tr14 region, which are available from the data archive
+ There is a python package for working with MUSE data: ~mpdaf~, which might or might not be useful
  + There is the option of working with /pixel tables/, which have not been resampled
  + This might help avoid some of the artefacts seen in the velocity maps
**** MUSE data on 30 Dor
+ This is in [[file:data/Tarantula/MUSE_R136toWill]]
+ Example of extracting coordinates for each pixel in the velocity maps is given in
  + [[file:data/Tarantula/MUSE_R136toWill/tarantula-ipython-session-2019-10-16.py]]


*** Larger scale patterns in Orion 
+ Haenel:1987a have maps at arcmin scale for whole nebula
+ [ ] Could extend velocity statistics for Orion by combining this with the Arthur:2016a Garcia-Diaz:2008a data
*** Extragalactic HII regions
+ Look at data like in Moiseev:2015a

*** Hubble X and Hubble V in Barnard's Galaxy NGC 6822
** Papers for Mariano
+ Damiani 2017 Lagoon
  + https://www.dropbox.com/s/xzouvpragh86bke/Damiani2017b-0.pdf?dl=0
+ Damiani 2016 Carina
  + https://www.dropbox.com/s/2t9emfwm7mzv995/Damiani2016a-0.pdf?dl=0
+ Arthur 2016 Orion
  + https://www.dropbox.com/s/73fge4zo8j10mx0/Arthur2016a-0.pdf
+ Medina 2014 Simulaciones
  + https://www.dropbox.com/s/9oxtmdh8kwqseky/Medina2014a-0.pdf?dl=0
+ García-Díaz 2008 Orion
  + https://www.dropbox.com/s/migybjp7ucwoxie/Garcia-Diaz2008a-0.pdf?dl=0
