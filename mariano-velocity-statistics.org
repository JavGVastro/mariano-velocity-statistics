* Coherence scales in H II regions

** Plan
+ Derive velocity structure functions for H II regions of different sizes:
  + Lagoon, Carina, Tarantula
+ Compare 

** Return to project 2021

*** Other things to do maybe

**** TODO Spatial variation in the structure function
+ Once we have found the correlation length, L_0, then we can look at the large-scale (> L_0) POS variation of the small-scale (< L_0) fluctuations.
+ In particular variation in
  + Magnitude of fluctuations: \sigma(< L_0)
  + Slope of structure function
  + And even in L_0 itself
    + Although for this, we need to be working on scales biggest than the largest local L_0
+ This should be easy to do with the pandas table method of doing the structure function, since we already have all the information - we just need to partition it up

**** TODO Polarization analogy for exploring anisotropy of structure function
+ This is an old idea that I had - explained in [[file:~/Dropbox/Org/garrelt-simulations.org][file:~/Dropbox/Org/garrelt-simulations.org]]
+ Might be fun to apply to structure functions.  Could also be used on brightness fluctuations
+ I wonder if there is prior art on something similar - I imagine that the Planck people have looked at anisotropy of density structures, as compared with magnetic field
  + Yes, I have found Planck-Collaboration:2016a
    + Planck intermediate results. XXXII. The relative orientation between the magnetic field and structures traced by interstellar dust
    + https://ui.adsabs.harvard.edu/abs/2016A%26A...586A.135P/abstract
    + Section 4 explains what they did - some sort of Hessian method
    + I still think there might be room for the Stokes parameters approach
    + They also mention "anisotropic wavelet techniques", which might be interesting
+ We could call it /polfluctuarization/ or something!

*** TODO Structure function of Tarantula
+ [2021-01-26 Tue] This is the first thing I am going to do in order to reactivate the project
+ The plan is to use it for the Javier paper, which will compare structure functions and other statistics for a range of H II regions with different sizes and luminosities
+ [X] Fix my multi-threaded strucfunc implementation
  + This is in
    + github: https://github.com/will-henney/muse-strucfunc
    + local: [[file:~/Dropbox/muse-strucfunc/][file:~/Dropbox/muse-strucfunc/]]
  + Now it works again, and faster than ever!
    + Multi-threaded version on my laptop is now twice as fast as it ever was on iMac at work
    + Time to calculate structure function for 400x400 array is 27.2 s

#+begin_src python :tangle tarantula-strucfunc.py :eval no
  import sys
  from pathlib import Path
  import json
  import numpy as np
  from astropy.io import fits
  sys.path.append("../muse-strucfunc")
  import strucfunc

  try:
      LINEID = sys.argv[1]
  except:
      LINEID = "ha"

  fitsfilename = {
      "ha": "GAUS_Ha6562.8_060_Will.fits",
      "nii": "GAUS_NII6583.45_060_Will.fits",
  }
  datadir = Path("data/Tarantula/MUSE_R136toWill")

  hdulist = fits.open(datadir / fitsfilename[LINEID])

  n = None
  sb = hdulist[1].data[:n, :n].astype(np.float64)
  vv = hdulist[2].data[:n, :n].astype(np.float64)
  ss = hdulist[3].data[:n, :n].astype(np.float64)

  # Replace spurious values in the arrays
  m = ~np.isfinite(sb*vv*ss) | (sb < 0.0)
  if LINEID == "nii":
      # Remove bad patch from the [N II] map
      m = m | (sb > 6e4) 
  sb[m] = 0.0
  vv[m] = np.nanmean(vv)
  sb /= sb.max()


  rslt = strucfunc.strucfunc_numba_parallel(vv, wmap=sb, dlogr=0.15)

  good = (~m) & (sb > 0.001)
  rslt["Unweighted mean velocity"] = np.mean(vv[good])
  rslt["Unweighted sigma^2"] = np.var(vv[good])
  v0w = rslt["Weighted mean velocity"] = np.average(vv, weights=sb)
  rslt["Weighted sigma^2"] = np.average((vv - v0w)**2, weights=sb)


  class MyEncoder(json.JSONEncoder):
      def default(self, obj):
          if isinstance(obj, np.integer):
              return int(obj)
          elif isinstance(obj, np.floating):
              return float(obj)
          elif isinstance(obj, np.ndarray):
              return obj.tolist()
          else:
              return super(MyEncoder, self).default(obj)

  jsonfilename = f"tarantula-strucfunc-{LINEID}.json"
  with open(jsonfilename, "w") as f:
      json.dump(rslt, fp=f, indent=3, cls=MyEncoder)
  print(jsonfilename, end="")
#+end_src

#+begin_src sh :results file
python tarantula-strucfunc.py
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc.json]]



**** Graph of Tarantula structure function

#+begin_src python :results file :return figfile
  import json
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns

  def bfunc(r, r0, sig2, m):
      "Theoretical structure function"
      C = 1.0 / (1.0 + (r/r0)**m)
      return 2.0*sig2*(1 - C)

  data = json.load(open("tarantula-strucfunc-ha.json"))

  sns.set_color_codes()
  fig, ax = plt.subplots(figsize=(5, 5))

  figfile = "tarantula-strucfunc-plot-ha.pdf"

  pixscale = 0.2 # arcsec
  pixscale *= 0.242               # parsec
  r = pixscale * 10**np.array(data["log10 r"])
  B = np.array(data["Unweighted B(r)"])
  sig2 = data["Unweighted sigma^2"]
  B_w = np.array(data["Weighted B(r)"])
  sig2_w = data["Weighted sigma^2"]

  # Plot fit to unweighted strucfunc
  rgrid = pixscale * np.logspace(0.0, 2.7)
  r0 = np.interp(sig2, B, r)
  m = 1.22
  flabel = rf"$m = {m:.2f}$, $r_0 = {r0:.1f}$ pc, $\sigma^2 = {sig2:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0, sig2, m - 0.1),
      bfunc(rgrid, r0, sig2, m + 0.1),
      color="k", alpha=0.1,
  )
  ax.plot(rgrid, bfunc(rgrid, r0, sig2, m), color="k", label=flabel)

  # Plot points from unweighted strucfunc
  ax.plot(r, B, 'o', label="Unweighted")


  # Plot fit to weighted strucfunc
  r0_w = np.interp(sig2_w, B_w, r)
  m_w = 1.30
  flabel_w = rf"$m = {m_w:.2f}$, $r_0 = {r0_w:.1f}$ pc, $\sigma^2 = {sig2_w:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0_w, sig2_w, m_w - 0.1),
      bfunc(rgrid, r0_w, sig2_w, m_w + 0.1),
      color="k", alpha=0.05,
  )
  ax.plot(rgrid, bfunc(rgrid, r0_w, sig2_w, m_w), lw=0.5, color="k", alpha=0.5, label=flabel_w)

  # Plot points from weighted strucfunc
  ax.plot(r, B_w, 'o', ms=3, alpha=0.5, label="Flux-weighted")


  melnick_r = np.array([2.5, 7.5, 12.5, 17.5, 22.5, 27.5])
  melnick_B = np.array([2.0, 2.1, 2.2, 2.2, 2.25, 2.25]) * 18.2**2
  ax.plot(melnick_r, melnick_B, 's', label="Melnick+ (2020)", color="y", zorder=-10)


  ax.axhline(sig2, color="k", ls="--")
  ax.axhline(sig2_w, color="r", ls=":")
  ax.legend(title=r"30 Doradus H$\alpha$")
  ax.set(
      xscale = "log",
      yscale = "log",
      ylim  = [0.5, 1500],
      xlabel = "Separation, pc",
      ylabel = r"$B(r)$, (km/s)$^2$",
  )
  fig.tight_layout()
  sns.despine()
  fig.savefig(figfile)
  fig.savefig(figfile.replace(".pdf", ".jpg"))
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc-plot-ha.pdf]]


Same but for the [N II] line

#+begin_src python :results file :return figfile
  import json
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns

  def bfunc(r, r0, sig2, m):
      "Theoretical structure function"
      C = 1.0 / (1.0 + (r/r0)**m)
      return 2.0*sig2*(1 - C)

  data = json.load(open("tarantula-strucfunc-nii.json"))

  sns.set_color_codes()
  fig, ax = plt.subplots(figsize=(5, 5))

  figfile = "tarantula-strucfunc-plot-nii.pdf"

  pixscale = 0.2 # arcsec
  pixscale *= 0.242               # parsec
  r = pixscale * 10**np.array(data["log10 r"])
  B = np.array(data["Unweighted B(r)"])
  sig2 = data["Unweighted sigma^2"]
  B_w = np.array(data["Weighted B(r)"])
  sig2_w = data["Weighted sigma^2"]

  rgrid = pixscale * np.logspace(0.0, 2.7)

  # Plot fit to unweighted strucfunc
  r0 = np.interp(sig2, B, r)
  m = 0.95
  flabel = rf"$m = {m:.2f}$, $r_0 = {r0:.1f}$ pc, $\sigma^2 = {sig2:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0, sig2, m - 0.1),
      bfunc(rgrid, r0, sig2, m + 0.1),
      color="k", alpha=0.1,
  )
  ax.plot(rgrid, bfunc(rgrid, r0, sig2, m), color="k", label=flabel)

  # Plot points from unweighted strucfunc
  ax.plot(r, B, 'o', label="Unweighted")


  # Plot fit to weighted strucfunc
  r0_w = np.interp(sig2_w, B_w, r)
  m_w = 1.05
  flabel_w = rf"$m = {m_w:.2f}$, $r_0 = {r0_w:.1f}$ pc, $\sigma^2 = {sig2_w:.0f}$ (km/s)$^2$"
  ax.fill_between(
      rgrid,
      bfunc(rgrid, r0_w, sig2_w, m_w - 0.1),
      bfunc(rgrid, r0_w, sig2_w, m_w + 0.1),
      color="k", alpha=0.05,
  )
  ax.plot(rgrid, bfunc(rgrid, r0_w, sig2_w, m_w), lw=0.5, color="k", alpha=0.5, label=flabel_w)

  # Plot points from weighted strucfunc
  ax.plot(r, B_w, 'o', ms=3, alpha=0.5, label="Flux-weighted")


  melnick_r = np.array([2.5, 7.5, 12.5, 17.5, 22.5, 27.5])
  melnick_B = np.array([2.0, 2.1, 2.2, 2.2, 2.25, 2.25]) * 18.2**2
  ax.plot(melnick_r, melnick_B, 's', label="Melnick+ (2020)", color="y", zorder=-10)


  ax.axhline(sig2, color="k", ls="--")
  ax.axhline(sig2_w, color="r", ls=":")
  ax.legend(title="30 Doradus [N II]")
  ax.set(
      xscale = "log",
      yscale = "log",
      ylim  = [0.5, 1500],
      xlabel = "Separation, pc",
      ylabel = r"$B(r)$, (km/s)$^2$",
  )
  fig.tight_layout()
  sns.despine()
  fig.savefig(figfile)
  fig.savefig(figfile.replace(".pdf", ".jpg"))
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc-plot-nii.pdf]]


Same but in parsec.

Distance = 50 kpc => 1 arcsec = 0.242 pc

#+begin_src python :results file :return figfile
  import json
  import numpy as np
  from matplotlib import pyplot as plt
  import seaborn as sns

  data = json.load(open("tarantula-strucfunc.json"))

  fig, ax = plt.subplots(figsize=(5, 5))

  figfile = "tarantula-strucfunc-plot-parsec.jpg"

  pixscale = 0.2                  # arcsec
  pixscale *= 0.242               # parsec
  r = pixscale * 10**np.array(data["log10 r"])
  B = np.array(data["Unweighted B(r)"])
  sig2 = data["Unweighted sigma^2"]
  B_w = np.array(data["Weighted B(r)"])
  sig2_w = data["Weighted sigma^2"]

  ax.plot(r, B, 'o')
  ax.plot(r, B_w, 'o')
  ax.axhline(sig2, color="k", ls="--")
  ax.axhline(sig2_w, color="r", ls=":")
  ax.set(
      xscale = "log",
      yscale = "log",
      xlabel = "Separation, parsec",
      ylabel = r"$B(r)$, (km/s)$^2$",
  )
  fig.tight_layout()
  sns.despine()
  fig.savefig(figfile)
  fig.savefig(figfile.replace(".jpg", ".pdf"))
#+end_src

#+RESULTS:
[[file:tarantula-strucfunc-plot-parsec.jpg]]



**** Sample results
What we got from test with pure python version with n = 20
#+begin_example
{'log10 r': array([0.  , 0.15, 0.3 , 0.45, 0.6 , 0.75, 0.9 , 1.05, 1.2 ]), 'Sum dv^2': array([  286.176572  ,  1816.08667744,  4456.64384807, 10247.69199721,
       15614.41156876, 17353.22440817, 39015.36434385, 40118.31285852,
        2608.48845663]), 'Sum weights': array([ 27.48855598,  50.72646818, 100.8550699 , 152.64575999,
       181.63544682, 149.66641101, 179.43422474,  99.73101336,
        13.14206985]), 'Sum w * dv^2': array([  188.07159422,  1119.13494059,  2684.97040556,  6123.48035994,
        8857.18554824,  9056.58693937, 18557.14879415, 17924.77263585,
        1209.60779833]), 'N pairs': array([ 52,  98, 191, 283, 345, 301, 382, 223,  28]), 'Unweighted B(r)': array([  5.50339562,  18.53149671,  23.33321386,  36.21092579,
        45.25916397,  57.65190833, 102.13446163, 179.90274824,
        93.16030202]), 'Weighted B(r)': array([  6.84181426,  22.06214982,  26.62206678,  40.11562693,
        48.76352993,  60.51182011, 103.42034147, 179.73117922,
        92.04088944])}
#+end_example


**** DONE Assessing the strategies
CLOSED: [2021-01-26 Tue 19:36]
+ So far I have had medium-size data sets, which have allowed the use of inefficient algorithms using pandas
+ Sizes of datsets
  + Damiani:2016a Carina
    + 866 spatial points
  + Damiani:2017b Lagoon
    + 1177 spatial points
  + Castro:2018a Tarantula (30 Dor)
    + 649 x 649 pixels => 421201 points
    + This is 400 x what I was doing before
  + Estimate of memory requirement to store all the pairs (assume 8 bytes per number)
    | N points | pairs = N^2 / 2 | Memory (GB) |
    |----------+----------------+-------------|
    |     1000 |         500000 |      0.0037 |
    |   421000 |    88620500000 |    660.2742 |
    #+TBLFM: $2=$1*$1/2::$3=8 $2 / 1024**3 ; f4
  + So that is not feasible - need to use the more efiicient algorithm.
  + Based on my tests so far, I estimate that the numba parallel algorithm should be able to do the Tarantula structure function in 27.2 (649/400)**4 = 188.5 s, or 3 minutes
    + *So that is fine*
*** Tarantula I-\sigma relation
#+begin_src python :eval no :tangle tarantula-I-sigma-hist.py 
  import sys
  from pathlib import Path
  from matplotlib import pyplot as plt
  import seaborn as sns
  import json
  import numpy as np
  from astropy.io import fits
  sys.path.append("../muse-strucfunc")
  import strucfunc

  try:
      LINEID = sys.argv[1]
  except:
      LINEID = "ha"

  try:
      METHOD = sys.argv[2]
  except:
      METHOD = "standard"

  USE_COLDEN = "colden" in METHOD
  USE_DEPTH = "depth" in METHOD

  fitsfilename = {
      "ha": "GAUS_Ha6562.8_060_Will.fits",
      "nii": "GAUS_NII6583.45_060_Will.fits",
  }
  wav0 = {"ha": 6562.8, "nii": 6583.45}
  atm_wt = {"ha": 1.0, "nii": 14.0}
  fs_var = {"ha": 10.233, "nii": 0.0}
  # Assume 1e4 K for thermal broadening
  thermal_var = 82.5 / atm_wt[LINEID]

  datadir = Path("data/Tarantula/MUSE_R136toWill")

  hdulist = fits.open(datadir / fitsfilename[LINEID])

  n = None
  sb = hdulist[1].data[:n, :n].astype(np.float64)
  vv = hdulist[2].data[:n, :n].astype(np.float64)
  ss = hdulist[3].data[:n, :n].astype(np.float64)

  # optionally use column density, instead of surface brightness
  if USE_COLDEN:
      dd = fits.open(datadir / "Density.fits")["DATA"].data[:n, :n].astype(np.float64)
      sb /= dd
  if USE_DEPTH:
      dd = fits.open(datadir / "Density.fits")["DATA"].data[:n, :n].astype(np.float64)
      sb /= dd**2


  # Convert sigma to km/s
  ss *= 3e5 / wav0[LINEID]

  # Subtract instrumental width and thermal width 
  ss = np.sqrt(ss**2 - 48.0**2 - fs_var[LINEID] - thermal_var)

  # Replace spurious values in the arrays
  m = ~np.isfinite(sb*vv*ss) | (sb < 0.0)
  if LINEID == "nii":
      # Remove bad patch from the [N II] map
      m = m | (sb > 6e4) 


  m = ~m                          # invert mask

  # additional mask for bright pixels
  # BRIGHT_THRESHOLD = 0.1*np.max(sb[m])
  BRIGHT_THRESHOLD = np.median(sb[m])
  mb = sb > BRIGHT_THRESHOLD

  # Brightness-weighted average sigma
  AV_SIG = np.average(ss[m], weights=sb[m])

  NBIN = 100
  BMAX = np.max(1.2*sb[m])
  BMIN = BMAX / 1000.0
  if USE_COLDEN:
      BMAX = 5*BRIGHT_THRESHOLD
      BMIN = BMAX / 100.0
  if USE_DEPTH:
      BMAX = 10*BRIGHT_THRESHOLD
      BMIN = BMAX / 500.0
  SMIN, SMAX = 0.0, 90.0
  VMIN, VMAX = 220.0, 330.0
  GAMMA = 1.5

  vlabel = "Centroid velocity, km/s"
  slabel = "RMS line width, km/s"
  blabel = "log10(Surface brightness)"
  if USE_COLDEN:
      blabel = "log10(Column density)"
  if USE_DEPTH:
      blabel = "log10(LOS depth)"

  fig, axes = plt.subplots(2, 2)

  linestyle = dict(lw=0.7, ls="--", color="r", alpha=0.5)

  # I - sigma
  xmin, xmax = np.log10(BMIN), np.log10(BMAX)
  ymin, ymax = SMIN, SMAX
  H, xedges, yedges = np.histogram2d(
      np.log10(sb[m]), ss[m], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  axes[0, 0].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  # Show brightness thereshold
  axes[0, 0].axvline(np.log10(BRIGHT_THRESHOLD), **linestyle)
  # Show average sigma
  axes[0, 0].axhline(AV_SIG, **linestyle)
  axes[0, 0].set(
      xlabel=blabel,
      ylabel=slabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )

  # I - V
  xmin, xmax = np.log10(BMIN), np.log10(BMAX)
  ymin, ymax = VMIN, VMAX
  H, xedges, yedges = np.histogram2d(
      np.log10(sb[m]), vv[m], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  axes[1, 0].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  # Show brightness thereshold
  axes[1, 0].axvline(np.log10(BRIGHT_THRESHOLD), **linestyle)
  axes[1, 0].set(
      xlabel=blabel,
      ylabel=vlabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )

  # V - sigma
  xmin, xmax = VMIN, VMAX
  ymin, ymax = SMIN, SMAX
  H, xedges, yedges = np.histogram2d(
      vv[m & (~mb)], ss[m & (~mb)], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  # Show average sigma
  axes[0, 1].axhline(AV_SIG, **linestyle)
  axes[0, 1].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  axes[0, 1].set(
      xlabel=vlabel,
      ylabel=slabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )


  # V - sigma but bright only
  xmin, xmax = VMIN, VMAX
  ymin, ymax = SMIN, SMAX
  H, xedges, yedges = np.histogram2d(
      vv[m & mb], ss[m & mb], 
      bins=[NBIN, NBIN],
      range=[[xmin, xmax], [ymin, ymax]],
  )
  axes[1, 1].imshow(
      (H.T)**(1.0/GAMMA), 
      extent=[xmin, xmax, ymin, ymax], 
      interpolation='none', aspect='auto', 
      origin='lower', cmap=plt.cm.gray_r,
  )
  # Show average sigma
  axes[1, 1].axhline(AV_SIG, **linestyle)
  axes[1, 1].set(
      xlabel=vlabel,
      ylabel=slabel,
      xlim=[xmin, xmax],
      ylim=[ymin, ymax],
  )

  fig.tight_layout()

  plotfile = f"tarantula-I-sigma-hist-{LINEID}.png"
  if USE_COLDEN:
      plotfile = plotfile.replace(".", "-colden.")
  if USE_DEPTH:
      plotfile = plotfile.replace(".", "-depth.")

  fig.savefig(plotfile, dpi=200)

  print(plotfile, end="")


#+end_src

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py ha
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-ha.png]]

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py nii
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-nii.png]]

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py ha colden
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-ha-colden.png]]

#+begin_src sh :results file 
  python tarantula-I-sigma-hist.py ha depth
#+end_src

#+RESULTS:
[[file:tarantula-I-sigma-hist-ha-depth.png]]

** LOS versus POS widths
+ Carina
  + Line widths typically have \sigma = 15 km/s, but this includes the thermal contribution.
  + thermal \sigma is 9 km/s => non-thermal is 12 km/s
  + For individual components, we have 5.6 km/s, so we have \sigma(LOS) = 2 \sigma(POS), as in Orion
+ 30 Doradus
  + We have \sigma = 55 km/s for H alpha at highest brightness
  + For Orion with the same instrument we have 48.5 km/s
  + Subtracting in quadrature gives 26 km/s for LOS \sigma
    + Note however, that 15 km/s is what Melnick et al found for the same region
      + Is this because they have decomposed the lines into components first
    + I need to check this with the original data
  + For POS \sigma we have sqrt(252) = 16 km/s
  + So, we have LOS and POS \sigma being the same if we believe Melnick, although the MUSE widths suggest LOS \sigma is 2 x higher
+ Orion
+ M8

** Comparison between regions
|             |     Q_H |  L(Ha) |    SFR |   n | R_S, pc | L, pc |   \Sigma_SFR | \ell_0, pc |   \sigma |    m | D, kpc |
|-------------+--------+--------+--------+-----+--------+-------+--------+--------+-----+------+--------|
| Orion       |   1e49 | 1.2e37 | 5.3e-5 | 1e4 |  0.101 |   0.6 | 46.862 |   0.05 | 3.1 |  1.1 |    0.4 |
| Orion large |   1e49 | 1.2e37 | 5.3e-5 | 100 |  2.184 |     4 |  1.054 |        |     |      |    0.4 |
| M8 small    |   2e49 | 2.3e37 | 1.0e-4 | 600 |  0.833 |    20 |  0.080 |    1.3 |   3 |  0.8 |    1.3 |
| M8 large    |   2e49 | 2.3e37 | 1.0e-4 |  60 |  3.868 |    20 |  0.080 |      6 |   4 |    1 |    1.3 |
| Carina      |   2e51 | 2.3e39 | 1.0e-2 | 500 |  4.368 |    15 | 14.147 |    0.5 |   4 |  0.7 |    2.0 |
| 30 Dor      | 2.5e51 | 2.9e39 | 1.3e-2 | 500 |  4.705 |    30 |  4.598 |    2.7 |  16 | 1.22 |     50 |
| NGC 604 T   |   1e51 | 1.2e39 | 5.3e-3 |  50 | 16.092 |   400 |  0.011 |     11 | 7.3 |  1.7 |    840 |
| NGC 595     |   5e50 | 5.8e38 | 2.6e-3 |  50 | 12.772 |   300 |  0.009 |     11 | 6.6 |  1.7 |    840 |
| Hubble V    |   3e49 | 3.5e37 | 1.5e-4 |  90 |  3.379 |   100 |  0.005 |    3.6 | 2.8 |  1.8 |    500 |
| Hubble X    |   6e49 | 7.0e37 | 3.1e-4 |  30 |  8.856 |   150 |  0.004 |    4.7 | 3.6 |  1.7 |    500 |
#+TBLFM: $3=$2/ 8.56e+11 ;s2::$4=4.424e-42 $3;s2::$6=($2 / 4 $pi 2.6e-13 $5**2 )**(1/3) / $pc;f3::$8=$4 / $pi ($7/1000)**2 ;f3


More recent census of stars in 30 Doradus gives slightly larger QH - Bestenlehner:2020a give 2.75e+51 /s

L(Ha) = (h\nu) \alpha_Ha VEM
Q_H = \alpha_B VEM = L(Ha) \alpha_B/\alpha_eff 1/h\nu

h\nu = 13.6 (1/4 - 1/9) eV = 3.026e-12 erg
\alpha_B / \alpha_eff = 2.6 

Q_H = 8.56e+11 L(Ha)

NGC 604: L(Ha) = 1e39 => Q_H = 1e51 erg
NGC 595: L(Ha) = 

Hubble V: L(Ha) = 1e49 en fotones => Q(H) = 2.6e49
Hubble X: L(Ha) = 2.4e49 en fotones => Q(H) = 6.24e49


** Velocity maps of Carina and Lagoon

+ Gaia-ESO spectroscopy
  + Damiani:2016a Carina
    + 10 arcmin at 2.3 kpc = 6 pc
    + 10 arcsec = 0.1 pc
    + Can analyze blue and red components separately and together
  + Damiani:2017b Lagoon
    + D = 1250 pc
    + Total extent: 0.8 deg = 17 pc
+ MUSE spectroscopy
  + McLeod:2016a Carina
    + 2 arcmin at 2.3 kpc = 1.3 pc
    + 1 arcsec = 0.01 pc
  + Mc-Leod:2016a Orion
    + 5 arcmin at 410 pc = 0.6 pc
    + 1 arcsec = 0.002 pc
    + Amplitude is about 10 km/s
  + Castro:2018a Tarantula (30 Dor)
    + These are excellent
    + 2 arcmin at 50 kpc = 30 pc
    + 1 arcsec = 0.242 pc
    + Amplitude is about 40 km/s
    + Looks like 5 arcsec is typical fluctuation scale => 1 pc
    + Anti correlation of intensity with \sigma(LOS) - see Fig 7
    + Could use density and de-extincted H\alpha to get LOS thickness
  + McLeod:2015a Eagle pillars
    + A bit too noisy to do much with
+ Longslit spectroscopy
  + Arthur:2016a Orion
    + Find scale of 0.05 pc decorrelation scale from struc func
    + Similar scale from power spectrum of brightness
    + Inner scale of 0.02 pc, but not clear what this is
** Other literature on Lagoon kinematics
+ Also see the images in introduction to my Greece talk
  + [[file:~/Dropbox/Presentations/Olympia2014/wjh-greece-2014.pdf]]
*** Relation to molecular/neutral gas
+ Tiwari:2018a have CO, etc for Lagoon region
  + Ionized gas is at negative velocities with respect to CO
    + Lada:1976a have +11 km/s LSR for CO at biggest clump
  + This is reminiscent of champagne flow, as in Orion
+ Esteban:1999a have multiple optical lines for M42 (Orion), M17 (Eagle), and M8 (Lagoon)
  + For Lagoon
    + Slit is 25 arcsec S of Hourglass
    + V(HEL) approx -2 km/s for low-ionization lines
    + Higher ionization lines are more like -10
    + Discrepant results for [O I] and [N I] but may suffer from sky line contamination
  + They find a velocity-IP correlation in all cases, indicating blue-shifted champagne flows
*** Dominant sources of ionizing radiation
+ Looks like main ionizing star (9 Sgr) is 1pc in front of cloud in Lagoon
  + From Fig 20 of Damiani:2017a
*** Prior art on Lagoon structure function
+ Chakraborty:1999a calculated the [O III] structure function of Hourglass region
  + Separations of 2-30 arcsec (so very little dynamic range)
  + As compared with up to 1800 arcsec in Damiani
  + They did something very strange to eliminate large scale gradients
  + And their absolute values are very large: saturates at 280 km^2/s^2
+ Chakraborty:1997a give [N II] velocity image but do not calculate statistics
  + And they don't even have absolute velocities
*** Previous studies of large scale kinematics
+ Haenel:1987a did FP spectroscopy of the entire nebula and has a grid at 50 arcsec resolution (0.014 deg)
  + 34 x 26 pixels = 0.5 x 0.4 degrees
  + Velocities are LSR
  + Seems to agree more or less with Damiani, given the 10 km/s difference between heliocentric and LSR
+ So this is very similar number of points to the Damiani data, but coverage is more uniform


** Stage 1 of Mariano project

*** DONE Download the Gaia-ESO datasets
CLOSED: [2018-09-25 Tue 08:41]
+ Damiani Carina
  + [[file:data/J_A+A_591_A74_table1.dat.fits]]
+ Damiani Lagoon
  + [[file:data/J_A+A_604_A135_table2.dat.fits]]

*** DONE Initial look at Carina data by Will
CLOSED: [2018-09-25 Tue 10:25]
See
 + Jupyter notebook: [[file:mariano-test.ipynb]]
 + Pure python version: [[file:mariano-test.py]]

*** TODO Initial look at Lagoon data by Mariano
+ [ ] Install required packages
+ [ ] Load data with astropy
+ [ ] Convert to pandas
+ [ ] Clean up data as necessary
+ [ ] Look at correlations
+ [ ] Make maps
+ [ ] Calculate structure functions


** Further stages
*** Obtain more data
**** MUSE data on Carina
+ McLeod:2016a best region is around "defiant finger", just to W of Keyhole.
  + That is the brightest region, and only one that overlaps the Gaia-ESO observations
  + Other regions are fainter and are in the periphery of the nebula
+ As well as the published McLeod:2016a stuff, there are new observations of the Tr14 region, which are available from the data archive
+ There is a python package for working with MUSE data: ~mpdaf~, which might or might not be useful
  + There is the option of working with /pixel tables/, which have not been resampled
  + This might help avoid some of the artefacts seen in the velocity maps
**** MUSE data on 30 Dor
+ This is in [[file:data/Tarantula/MUSE_R136toWill]]
+ Example of extracting coordinates for each pixel in the velocity maps is given in
  + [[file:data/Tarantula/MUSE_R136toWill/tarantula-ipython-session-2019-10-16.py]]


*** Larger scale patterns in Orion 
+ Haenel:1987a have maps at arcmin scale for whole nebula
+ [ ] Could extend velocity statistics for Orion by combining this with the Arthur:2016a Garcia-Diaz:2008a data
*** Extragalactic HII regions
+ Look at data like in Moiseev:2015a

*** Hubble X and Hubble V in Barnard's Galaxy NGC 6822
** Papers for Mariano
+ Damiani 2017 Lagoon
  + https://www.dropbox.com/s/xzouvpragh86bke/Damiani2017b-0.pdf?dl=0
+ Damiani 2016 Carina
  + https://www.dropbox.com/s/2t9emfwm7mzv995/Damiani2016a-0.pdf?dl=0
+ Arthur 2016 Orion
  + https://www.dropbox.com/s/73fge4zo8j10mx0/Arthur2016a-0.pdf
+ Medina 2014 Simulaciones
  + https://www.dropbox.com/s/9oxtmdh8kwqseky/Medina2014a-0.pdf?dl=0
+ García-Díaz 2008 Orion
  + https://www.dropbox.com/s/migybjp7ucwoxie/Garcia-Diaz2008a-0.pdf?dl=0
